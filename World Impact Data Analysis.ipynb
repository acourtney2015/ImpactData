{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To work with this notebook you must have Anaconda installed on your computer. To be sure you have all the packages installed and running normally you can run the cells with import statements and look for any error messages. If you get an error download the missing package and pip install from the command line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First Import Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next import your data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am using data from the World Bank. The primary World Bank collection of development indicators, compiled from officially-recognized international sources. It presents the most current and accurate global development data available, and includes national, regional and global estimates. The topics covered are: Agriculture & Rural Development, Aid Effectiveness, Climate Change, Economy & Growth, Education, Energy & Mining, Environment, External Debt, Financial Sector, Gender, Health, Infrastructure, Labor & Social Protection, Poverty, Private Sector, Public Sector, Science & Technology, Social Development, Trade, Urban Development. From the economies of the countries of WLD, EAP, ECA, LAC, MNA, SAS, SSA, HIC, LMY, IBRD, IDA gathered from 1960 - 2015, a time series covering 217 economies\n",
    "http://data.worldbank.org/data-catalog/world-development-indicators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Wdata = pd.read_csv(\"WorldData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next look at a snapshot of your data file. We will see the statistics for each year as a sample of the years in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               1960          1961          1962          1963          1964  \\\n",
      "count  2.587000e+04  2.993500e+04  3.190800e+04  3.217500e+04  3.272300e+04   \n",
      "mean   2.668505e+11  2.459610e+11  2.434990e+11  2.434428e+11  2.538379e+11   \n",
      "std    7.405405e+12  7.346839e+12  7.488231e+12  7.398136e+12  7.627142e+12   \n",
      "min   -8.181071e+13 -9.465063e+13 -1.071675e+14 -1.181558e+14 -1.319199e+14   \n",
      "25%    6.099798e+00  6.521122e+00  6.641570e+00  6.905873e+00  7.254888e+00   \n",
      "50%    7.055984e+01  6.567180e+01  6.565022e+01  6.345300e+01  6.501782e+01   \n",
      "75%    1.148247e+07  3.293826e+06  2.280636e+06  2.429516e+06  2.799999e+06   \n",
      "max    4.645807e+14  4.921465e+14  5.037593e+14  4.898643e+14  5.048614e+14   \n",
      "\n",
      "               1965          1966          1967          1968          1969  \\\n",
      "count  3.563500e+04  3.521800e+04  3.680100e+04  3.658100e+04  3.728600e+04   \n",
      "mean   2.509145e+11  2.703316e+11  2.763226e+11  3.136419e+11  3.387058e+11   \n",
      "std    7.720802e+12  8.182320e+12  8.518432e+12  9.636761e+12  1.049887e+13   \n",
      "min   -1.555435e+14 -1.778706e+14 -2.055397e+14 -2.332403e+14 -2.810371e+14   \n",
      "25%    6.864804e+00  7.505992e+00  7.535158e+00  8.107377e+00  8.103910e+00   \n",
      "50%    6.813000e+01  6.994532e+01  7.412727e+01  7.331918e+01  7.479650e+01   \n",
      "75%    4.994800e+06  7.548546e+06  6.695460e+06  9.710000e+06  9.161820e+06   \n",
      "max    5.137691e+14  5.246661e+14  5.324264e+14  5.954208e+14  6.531940e+14   \n",
      "\n",
      "           ...               2006          2007          2008          2009  \\\n",
      "count      ...       1.927180e+05  1.964410e+05  1.942000e+05  1.938040e+05   \n",
      "mean       ...       1.170021e+12  1.337672e+12  1.513238e+12  1.587325e+12   \n",
      "std        ...       4.619001e+13  4.895210e+13  5.527025e+13  5.877300e+13   \n",
      "min        ...      -6.200057e+15 -1.691820e+14 -4.636015e+14 -1.962195e+14   \n",
      "25%        ...       6.000000e+00  5.911094e+00  5.800000e+00  5.578583e+00   \n",
      "50%        ...       5.342952e+01  5.348754e+01  5.484007e+01  5.393613e+01   \n",
      "75%        ...       4.074750e+06  3.589000e+06  4.415000e+06  4.970000e+06   \n",
      "max        ...       5.686502e+15  5.987072e+15  6.176068e+15  6.497584e+15   \n",
      "\n",
      "               2010          2011          2012          2013          2014  \\\n",
      "count  2.027780e+05  1.934110e+05  1.917990e+05  1.783530e+05  1.617560e+05   \n",
      "mean   1.811151e+12  2.150343e+12  2.337625e+12  2.729287e+12  3.225944e+12   \n",
      "std    6.894774e+13  8.022454e+13  8.823773e+13  1.034927e+14  1.199846e+14   \n",
      "min   -1.881552e+14 -2.328301e+14 -2.499456e+14 -2.830252e+14 -3.523014e+14   \n",
      "25%    5.624081e+00  6.000000e+00  5.700000e+00  5.761294e+00  5.000000e+00   \n",
      "50%    5.259992e+01  5.560000e+01  5.620000e+01  5.783229e+01  5.740000e+01   \n",
      "75%    2.927529e+06  5.864000e+06  5.454801e+06  1.197508e+07  2.579375e+07   \n",
      "max    6.864133e+15  7.831726e+15  8.649662e+15  9.621569e+15  1.105813e+16   \n",
      "\n",
      "               2015  \n",
      "count  6.623700e+04  \n",
      "mean   6.163739e+12  \n",
      "std    1.645258e+14  \n",
      "min   -3.752752e+14  \n",
      "25%    5.188637e+00  \n",
      "50%    6.240519e+01  \n",
      "75%    5.836316e+08  \n",
      "max    1.154079e+16  \n",
      "\n",
      "[8 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print (Wdata.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next do you need to clean the data? If so try this short line of code to clean the data remove any NULL or Nan or blank spaces and replace with anything you want here we are replacing all NULL with zero, or you can replace with the means etc depending upon your data and how/if it will affect your statistical output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WData2 = Wdata.fillna(\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next give your new file a name- here I called the file WDataClean- and extract as a csv file to work with moving forward. When you run the code below it will download the file to your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WData2.to_csv(\"WDataClean.csv\", index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next import Random Forest  Classifier from sklearn and a cross validation package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next ask pandas to read in your new cleaned file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WC = pd.read_csv(\"WDataClean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Next tell Random Forest what columns you want to use as your predictor. choose from your data describe call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(categorical_features='all', dtype= np.float,\n",
    "       handle_unknown='error', n_values='auto', sparse=True)\n",
    "def fit(self, X, y=None, **kwargs):\n",
    " enc.fit( X,y)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc.transform([[0,1,20]]).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Row Labels   Sum of 2015  \\\n",
      "0                                         Afghanistan  1.549330e+13   \n",
      "1   2005 PPP conversion factor, GDP (LCU per inter...  0.000000e+00   \n",
      "2   2005 PPP conversion factor, private consumptio...  0.000000e+00   \n",
      "3             Access to electricity (% of population)  0.000000e+00   \n",
      "4   Access to electricity, rural (% of rural popul...  0.000000e+00   \n",
      "5   Access to electricity, urban (% of urban popul...  0.000000e+00   \n",
      "6          Access to non-solid fuel (% of population)  0.000000e+00   \n",
      "7   Access to non-solid fuel, rural (% of rural po...  0.000000e+00   \n",
      "8   Access to non-solid fuel, urban (% of urban po...  0.000000e+00   \n",
      "9   Account at a financial institution (% age 15+)...  0.000000e+00   \n",
      "10  Account at a financial institution, female (% ...  0.000000e+00   \n",
      "11  Account at a financial institution, income, po...  0.000000e+00   \n",
      "12  Account at a financial institution, income, ri...  0.000000e+00   \n",
      "13  Account at a financial institution, male (% ag...  0.000000e+00   \n",
      "14  Adequacy of social insurance programs (% of to...  0.000000e+00   \n",
      "\n",
      "     Sum of 2014   Sum of 2013  \n",
      "0   1.520970e+13  1.513710e+13  \n",
      "1   0.000000e+00  0.000000e+00  \n",
      "2   0.000000e+00  0.000000e+00  \n",
      "3   0.000000e+00  0.000000e+00  \n",
      "4   0.000000e+00  0.000000e+00  \n",
      "5   0.000000e+00  0.000000e+00  \n",
      "6   0.000000e+00  0.000000e+00  \n",
      "7   0.000000e+00  0.000000e+00  \n",
      "8   0.000000e+00  0.000000e+00  \n",
      "9   9.961000e+00  0.000000e+00  \n",
      "10  3.812426e+00  0.000000e+00  \n",
      "11  6.619139e+00  0.000000e+00  \n",
      "12  1.220380e+01  0.000000e+00  \n",
      "13  1.578467e+01  0.000000e+00  \n",
      "14  0.000000e+00  0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "# Let's peak at some of the data. You can change the number to reflect how many headers you want to see\n",
    "print (WC.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Name what you want to use as your predictors.\n",
    "predictors = [\"Row Labels\", \"Sum of 2014\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make a prediction of accuracy based upon the data and the predictors you choose and choose what you want to predict. The data will be broken into cross validation pieces to improve accuracy using 3 folds. Assign the result to scores and Print scores as a mean of all three scores you will obtain from the algorithmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
    "scores = cross_validation.cross_val_score(alg, NameOfYourDataSetHere[predictors], NameOfYourDataSetHere[\"Sum of 2013\"], cv=3)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wow years are a terrible predictor of the country, as we expected. A few things might be wrong. Maybe we need to further clean and transform the data to get a better predictor and also maybe we are terrible at choosing the right features that make a good prediction.Next let's see if the computer can help with choosing the best features to select as predictors\n",
    "# Let's import a new series of packages to help with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#..and let's work with a portion of the dataset using just the world data and the data has been transformed. Most of the work in machine learning comes from cleaning and working with the best dataset. Let's import only data taken from the original dataset on one country- here Afghanistan. Let's look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#If the code throws errors you need to clean and transform your data more remember sklearn does not take strings only numbers and arrays. Try the code below to change all column to floats if you through floats errors\n",
    " predictions = alg.predict_proba(YourDataSetNameHere[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Row Labels   Sum of 2015  \\\n",
      "0                                         Afghanistan  1.549330e+13   \n",
      "1   2005 PPP conversion factor, GDP (LCU per inter...  0.000000e+00   \n",
      "2   2005 PPP conversion factor, private consumptio...  0.000000e+00   \n",
      "3             Access to electricity (% of population)  0.000000e+00   \n",
      "4   Access to electricity, rural (% of rural popul...  0.000000e+00   \n",
      "5   Access to electricity, urban (% of urban popul...  0.000000e+00   \n",
      "6          Access to non-solid fuel (% of population)  0.000000e+00   \n",
      "7   Access to non-solid fuel, rural (% of rural po...  0.000000e+00   \n",
      "8   Access to non-solid fuel, urban (% of urban po...  0.000000e+00   \n",
      "9   Account at a financial institution (% age 15+)...  0.000000e+00   \n",
      "10  Account at a financial institution, female (% ...  0.000000e+00   \n",
      "11  Account at a financial institution, income, po...  0.000000e+00   \n",
      "12  Account at a financial institution, income, ri...  0.000000e+00   \n",
      "13  Account at a financial institution, male (% ag...  0.000000e+00   \n",
      "14  Adequacy of social insurance programs (% of to...  0.000000e+00   \n",
      "\n",
      "     Sum of 2014   Sum of 2013  \n",
      "0   1.520970e+13  1.513710e+13  \n",
      "1   0.000000e+00  0.000000e+00  \n",
      "2   0.000000e+00  0.000000e+00  \n",
      "3   0.000000e+00  0.000000e+00  \n",
      "4   0.000000e+00  0.000000e+00  \n",
      "5   0.000000e+00  0.000000e+00  \n",
      "6   0.000000e+00  0.000000e+00  \n",
      "7   0.000000e+00  0.000000e+00  \n",
      "8   0.000000e+00  0.000000e+00  \n",
      "9   9.961000e+00  0.000000e+00  \n",
      "10  3.812426e+00  0.000000e+00  \n",
      "11  6.619139e+00  0.000000e+00  \n",
      "12  1.220380e+01  0.000000e+00  \n",
      "13  1.578467e+01  0.000000e+00  \n",
      "14  0.000000e+00  0.000000e+00  \n"
     ]
    }
   ],
   "source": [
    "print(WC.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add all your possible column choices of features for the computer to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Predictor1\", \"Predictor2\",\"Predictor3\",\"Predictor4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, NameOfYourDataSetHere[predictors], NameOfYourDataSetHere[\"WhatYouWantToPredict\"], cv=3)\n",
    "print (scores.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ask the computer to perform feature selection based upon the predictors and choosing your column to predict\n",
    "selector = SelectKBest(f_classif, k='5')\n",
    "selector.fit(NameOfYourDataSet[predictors], NameOfYourDataSet[\"WhatYouWantToPredict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the scores.So you can visually see and choose you best predictor\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now pick only the best features chosen by the computer's algorithmn above-you can choose as many as you like and re-run the analysis of prediction for accuracy and print the resulting new accuracy scores. Was it better or worse than what you choose as the predictors of what you wanted to predict? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = [\"Predictor1\", \"Predictor2\", \"Predictor3\", \"predictor4\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, NameOfYourDataSet[predictors], NameOfYourDataSet[\"WhatYouWantToPredict\"], cv=3)\n",
    "print (scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#You can now run this algorithm on any cleaned dataset you choose to import to predict your chosen outcome and make decisions\n",
    "#based upon the accuracy of the prediction and the features you selected\n",
    "#Just follow the same steps for the new dataset and change your predictors based on the available data in the dataset.Nice!\n",
    "#Yea!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Now you can choose to invest in a sector that will have the most impact on your chosen outcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
